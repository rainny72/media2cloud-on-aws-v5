// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
// SPDX-License-Identifier: Apache-2.0
const {
  join,
} = require('node:path');
const {
  readFileSync,
} = require('node:fs');
const {
  MIME_JPEG,
  imageFromS3,
  imageFromBuffer,
  imageFromScratch,
  computeHash,
  computeLaplacianVariance,
  distanceToBlack,
  computeBlackLevel,
} = require('../jimpHelper');
const {
  download,
  uploadFile,
} = require('../commonUtils');
const {
  cosdist,
} = require('../simpleMath');
const {
  loadModelConfigs,
  getModel,
} = require('./modelFactory');
const {
  TYPE_BLACKFRAMES,
  TYPE_MONOCHROMEFRAMES,
  TAG_ABSOLUTESILENT,
  TAG_VERYQUIET,
} = require('./definitions');

const {
  ENV_PROXY_BUCKET: ProxyBucket,
  ENV_BEDROCK_MODELLIST_LOCATION: ModelListLocation = '_settings/availablemodels.json',
} = process.env;

// https://docs.anthropic.com/en/docs/build-with-claude/vision#evaluate-image-size
const MAX_FRAMESEQUENCE_IMAGES = 10;
const MAX_IMAGE_WXH = [1456, 1456];
const SCENE_WXH = [364, 204]; // [284, 160];
const SHOT_WXH = [364, 204];
const BORDER_SIZE = 2;
const DISTANCE_THRESHOLD = 0.0050;

let EmbeddingModel;

async function _getEmbeddingModel(bucket, key) {
  if (EmbeddingModel !== undefined) {
    return EmbeddingModel;
  }

  let proxyBucket = bucket;
  let location = key;
  if (!proxyBucket) {
    proxyBucket = ProxyBucket;
  }
  if (!location) {
    location = ModelListLocation;
  }

  await loadModelConfigs(proxyBucket, location);

  EmbeddingModel = await getModel('titan-embed');
  return EmbeddingModel;
}

async function _generateTitanEmbedding(image) {
  const model = await _getEmbeddingModel();
  const { response } = await model.inference(undefined, [{ image }]);
  return response;
}

async function _createSequenceImage(bucket, prefix, item, frames, maxSequenceImages) {
  let gridWxH = SCENE_WXH;

  if (item.shot !== undefined) {
    gridWxH = SHOT_WXH;
  }

  if (item.shot !== undefined) {
    console.log(`PROCESSING SHOT#${item.shot}: ${frames.length} frames.`);
  } else {
    console.log(`PROCESSING SCENE#${item.scene}: ${frames.length} frames.`);
  }

  let sequenceImages = await _tileImages(bucket, prefix, frames, gridWxH, maxSequenceImages);

  let promises = [];
  for (const sequenceImage of sequenceImages) {
    promises.push(sequenceImage.getBufferAsync(MIME_JPEG));
  }
  sequenceImages = await Promise.all(promises);

  let id;
  let subdir;

  if (item.shot !== undefined) {
    id = `SH${String(item.shot).padStart(3, '0')}`;
    subdir = 'shots';
  } else if (item.scene !== undefined) {
    id = `SC${String(item.scene).padStart(3, '0')}`;
    subdir = 'scenes';
  }

  promises = [];
  for (let i = 0; i < sequenceImages.length; i += 1) {
    const jpeg = `${id}_${String(i).padStart(3, '0')}.jpg`;
    promises.push(uploadFile(bucket, join(prefix, subdir), jpeg, sequenceImages[i])
      .then(() =>
        join(subdir, jpeg)));
  }

  const names = await Promise.all(promises);

  return {
    ...item,
    frameSequences: names,
  };
}

async function _tileImages(
  bucket,
  prefix,
  frames,
  maxWxH = SCENE_WXH,
  maxFrameSequenceImages = MAX_FRAMESEQUENCE_IMAGES
) {
  if (!frames || frames.length === 0) {
    return [];
  }

  // check the image size and orientation
  const key = join(prefix, frames[0].name);
  const image = await imageFromS3(bucket, key);

  const imgW = image.bitmap.width;
  const imgH = image.bitmap.height;

  let factor = maxWxH[0] / imgW;

  // Portrait mode?
  if (imgH > imgW) {
    factor = maxWxH[0] / imgH;
  }

  const tileW = Math.round((factor * imgW) / 2) * 2;
  const tileH = Math.round((factor * imgH) / 2) * 2;

  const nCol = Math.floor(MAX_IMAGE_WXH[0] / tileW);
  const nRow = Math.floor(MAX_IMAGE_WXH[1] / tileH);

  // max number of frame images per image
  const numFramesPerImage = nCol * nRow;

  const selectedFrames = _getFrameSubset(
    frames,
    numFramesPerImage,
    maxFrameSequenceImages
  );

  console.log(`_getFrameSubset: ${frames.length} -> ${selectedFrames.length} [numFramesPerImage=${numFramesPerImage}, maxFrameSequenceImages=${maxFrameSequenceImages}, ColxRow=${nCol}x${nRow}]`);

  let images = [];

  while (selectedFrames.length > 0) {
    const framesPerImage = selectedFrames.splice(0, numFramesPerImage);

    images.push(_tileImage(
      bucket,
      prefix,
      framesPerImage,
      [tileW, tileH],
      [nCol, nRow]
    ));
  }

  images = await Promise.all(images);

  return images;
}

async function _tileImage(
  bucket,
  prefix,
  frames,
  tileWxH,
  grid,
  borderSize = BORDER_SIZE
) {
  const nCol = grid[0];
  const nRow = Math.ceil(frames.length / nCol);

  // pad frames to fill the grid
  const lastFrame = frames[frames.length - 1];
  const padding = (nCol * nRow) - frames.length;
  for (let i = 0; i < padding; i += 1) {
    frames.push(lastFrame);
  }

  const [tileW, tileH] = tileWxH;
  const compositeW = tileW * nCol;
  const compositeH = tileH * nRow;

  const frameSequenceImage = await imageFromScratch(compositeW, compositeH);

  for (let row = 0; row < nRow && frames.length > 0; row += 1) {
    for (let col = 0; col < nCol && frames.length > 0; col += 1) {
      const frame = frames.shift();
      const key = join(prefix, frame.name);

      const frameImage = await imageFromS3(bucket, key)
        .then((img) => {
          const w = tileW - (borderSize * 2);
          const h = tileH - (borderSize * 2);
          return img.resize(w, h);
        });

      const l = col * tileW + borderSize;
      const t = row * tileH + borderSize;
      frameSequenceImage.blit(frameImage, l, t);
    }
  }

  return frameSequenceImage.quality(80);
}

function _getEquallyDistributedSubset(frames, framesPerImage, maxImages) {
  const maxFrames = framesPerImage * maxImages;
  const step = Math.ceil(frames.length / maxFrames);

  let selected = [];
  const secondPass = [];

  for (let i = 0; i < frames.length; i += 1) {
    if ((i % step) === 0) {
      selected.push(frames[i]);
    } else {
      secondPass.push(frames[i]);
    }

    if (selected.length >= maxFrames) {
      break;
    }
  }

  let remaining = selected.length % framesPerImage;
  if (remaining > 0) {
    remaining = framesPerImage - remaining;
    secondPass.sort((a, b) =>
      b.laplacian - a.laplacian);

    selected = selected.concat(secondPass.splice(0, remaining));
  }

  return selected;
}

function _getFrameDistances(frames = []) {
  const dists = [];

  for (let i = 1; i < frames.length; i += 1) {
    const embedA = frames[i - 1].embedding;
    const embedB = frames[i].embedding;
    const d = cosdist(embedA, embedB);
    dists.push({ from: i - 1, to: i, d });
  }

  dists.sort((a, b) => b.d - a.d);

  return dists;
}

function _samplingFrames(frames, minDistance = 300) {
  const duped = frames.slice();
  const samples = [duped[0]];
  for (let i = 1; i < duped.length; i += 1) {
    const pre = samples[samples.length - 1];
    const cur = duped[i];
    if ((cur.timestampMillis - pre.timestampMillis) >= minDistance) {
      samples.push(cur);
    }
  }
  return samples;
}

function _getFrameByDistances(frames, framesPerImage, maxImages) {
  const indices = [];
  const selected = [];

  const filtered = _samplingFrames(frames, 300); // 300ms

  let dists = _getFrameDistances(filtered);
  dists = dists.slice(0, framesPerImage * maxImages);

  while (dists.length) {
    const { from, to, d } = dists.shift();

    if (d < DISTANCE_THRESHOLD) {
      break;
    }

    for (const idx of [from, to]) {
      if (!indices.includes(idx)) {
        selected.push(filtered[idx]);
        indices.push(idx);
      }
    }
  }

  // fill the image
  let remaining = selected.length % framesPerImage;
  if (remaining > 0) {
    remaining = framesPerImage - remaining;
    while (dists.length > 0) {
      if (remaining <= 0) {
        break;
      }

      const { from, to } = dists.shift();
      for (const idx of [from, to]) {
        if (remaining > 0 && !indices.includes(idx)) {
          selected.push(filtered[idx]);
          indices.push(idx);
          remaining -= 1;
        }
      }
    }
  }

  return selected;
}

function _getFrameSubset(frames, framesPerImage, maxImages) {
  if (!Array.isArray(frames) || !framesPerImage || !maxImages) {
    return [];
  }

  if (frames.length <= framesPerImage) {
    return frames;
  }

  let selected = _getFrameByDistances(frames, framesPerImage, maxImages);
  if (selected.length === 0) {
    selected = _getEquallyDistributedSubset(frames, framesPerImage, maxImages);
  }

  selected.sort((a, b) =>
    a.frameNum - b.frameNum);

  return selected;
}

async function _computeFrameProperties(fileOrS3Obj, blackFilter, includeEmbedding = true) {
  const frameProps = {};
  const promises = [];

  let buf;

  if (typeof fileOrS3Obj === 'string') {
    buf = readFileSync(fileOrS3Obj);
  } else if (typeof fileOrS3Obj === 'object') {
    const { bucket, key } = fileOrS3Obj;
    if (!bucket || !key) {
      throw new Error(`ERR: _computeFrameProperties: ${fileOrS3Obj} not supported`);
    }
    buf = await download(bucket, key, false)
      .then((res) =>
        res.Body.transformToByteArray());
    buf = Buffer.from(await buf);
  }

  if (includeEmbedding) {
    promises.push(_generateTitanEmbedding(buf.toString('base64'))
      .then((res) => {
        frameProps.embedding = res.embedding;
      }));
  }

  promises.push(imageFromBuffer(buf)
    .then((image) => {
      frameProps.hash = computeHash(image);
      frameProps.laplacian = computeLaplacianVariance(image);

      const distance = distanceToBlack(frameProps.hash);
      if (distance < 0.10 || frameProps.laplacian === 0) {
        const colorProps = computeBlackLevel(image, blackFilter);
        if (colorProps !== undefined) {
          const { wxh: [w, h] } = colorProps;

          colorProps.totalPixels = w * h;
          delete colorProps.wxh;

          frameProps.colorProps = colorProps;
          if (frameProps.colorProps.isBlack) {
            frameProps.knownType = TYPE_BLACKFRAMES;
          } else if (frameProps.colorProps.isMonochrome) {
            frameProps.knownType = TYPE_MONOCHROMEFRAMES;
          }
        }
      }
    }));

  await Promise.all(promises);

  return frameProps;
}

function _getLoudnessTimestamps(loudnesses = []) {
  const tags = [TAG_ABSOLUTESILENT, TAG_VERYQUIET];
  const loudTimestamps = [];

  for (const loudness of loudnesses) {
    const { label } = loudness;
    if (tags.includes(label)) {
      loudTimestamps.push(loudness);
    }
  }
  return loudTimestamps;
}

function _tageAudioMetadataToFrames(frames, loudnesses, pauseInDialogues) {
  const loudnessTimestamps = _getLoudnessTimestamps(loudnesses);
  const pauseTimestamps = (pauseInDialogues || []).slice();

  for (const frame of frames) {
    const {
      timestampMillis: t,
      loudnessLevel,
      pauseInDialogue,
    } = frame;

    if (loudnessLevel === undefined) {
      while (loudnessTimestamps.length) {
        const {
          label,
          timestampRange: [lmin, lmax],
        } = loudnessTimestamps[0];

        if (t > lmax) {
          loudnessTimestamps.shift();
          continue;
        }

        if (t < lmin) {
          break;
        }

        frame.loudnessLevel = label;
        break;
      }
    }

    if (pauseInDialogue === undefined) {
      while (pauseTimestamps.length) {
        const [pmin, pmax] = pauseTimestamps[0];

        if (t > pmax) {
          pauseTimestamps.shift();
          continue;
        }

        if (t < pmin) {
          break;
        }

        frame.pauseInDialogue = true;
        break;
      }
    }
  }

  return frames;
}

////////////////////////////////////////////////////
// Functions to export
////////////////////////////////////////////////////
async function createSequenceImage(bucket, prefix, item, frames, maxSequenceImages = MAX_FRAMESEQUENCE_IMAGES) {
  return await _createSequenceImage(bucket, prefix, item, frames, maxSequenceImages);
}

async function computeFrameProperties(fileOrBuffer, blackFilter, includeEmbedding) {
  return await _computeFrameProperties(fileOrBuffer, blackFilter, includeEmbedding);
}

function frameGroupAttributes(frameGroup) {
  frameGroup.sort((a, b) => a.frameNum - b.frameNum);

  const firstFrame = frameGroup[0];
  const lastFrame = frameGroup[frameGroup.length - 1];

  const frameRange = [firstFrame.frameNum, lastFrame.frameNum];
  const timestampRange = [firstFrame.timestampMillis, lastFrame.timestampMillis];
  const smpteTimecodes = [firstFrame.smpteTimecode, lastFrame.smpteTimecode];
  const knownType = firstFrame.knownType;

  const groupAttribute = {
    frameRange,
    timestampRange,
    smpteTimecodes,
    knownType,
  };

  const pauseAttributes = aggregatePauseAttributes(frameGroup);
  const loudnessAttributes = aggregateLoudnessAttributes(frameGroup);

  if (pauseAttributes.length === 2) {
    const [pauseInDialogue, pauseDuration] = pauseAttributes;
    groupAttribute.pauseInDialogue = pauseInDialogue;
    groupAttribute.pauseDuration = pauseDuration;
  }

  if (loudnessAttributes.length === 1) {
    const [loudnessLevel] = loudnessAttributes;
    groupAttribute.loudnessLevel = loudnessLevel;
  }

  return groupAttribute;
}

function tagAudioMetadataToFrames(frames, loudnesses, pauseInDialogues) {
  const framesWithMetadata = _tageAudioMetadataToFrames(frames, loudnesses, pauseInDialogues);

  return framesWithMetadata;
}

function aggregateLoudnessAttributes(frames) {
  const loudnessLevels = [frames[0].loudnessLevel];
  for (let i = 1; i < frames.length; i += 1) {
    if (loudnessLevels[0] !== frames[i].loudnessLevel) {
      break;
    }
  }

  // at least two consecutive loudness level
  if (loudnessLevels.length > 1) {
    const loudnessLevel = loudnessLevels[0];
    return [loudnessLevel];
  }

  return [];
}

function aggregatePauseAttributes(frames) {
  const pauseTimestamps = [];
  for (const frame of frames) {
    if (frame.pauseInDialogue !== true) {
      break;
    }
    pauseTimestamps.push(frame.timestampMillis);
  }

  // at least two consecutive pauses
  if (pauseTimestamps.length > 1) {
    const pauseInDialogue = true;
    const pauseDuration = pauseTimestamps[pauseTimestamps.length - 1] - pauseTimestamps[0];
    return [pauseInDialogue, pauseDuration];
  }

  return [];
}

module.exports = {
  createSequenceImage,
  computeFrameProperties,
  frameGroupAttributes,
  tagAudioMetadataToFrames,
  aggregatePauseAttributes,
  aggregateLoudnessAttributes,
};
